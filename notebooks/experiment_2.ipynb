{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7f9d2e",
   "metadata": {},
   "source": [
    "Adapted from https://www.learnpytorch.io/06_pytorch_transfer_learning/ and https://www.learnpytorch.io/05_pytorch_going_modular/#2-create-datasets-and-dataloaders-data_setuppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f136fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a532fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from timeit import default_timer as timer\n",
    "import torch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6105cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(source_folder, output_folder, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Splits image data from subfolders in a source folder into train and test sets\n",
    "    in an output folder, maintaining the subfolder structure.\n",
    "\n",
    "    Args:\n",
    "        source_folder (str): Path to the folder containing the class subfolders.\n",
    "        output_folder (str): Path to the folder where 'train' and 'test' folders\n",
    "                             will be created.\n",
    "        train_ratio (float): Proportion of images to allocate to the training set\n",
    "                             (default is 0.8 for 80%).\n",
    "    \"\"\"\n",
    "    print(f\"Source folder: {os.path.abspath(source_folder)}\")\n",
    "    print(f\"Output folder: {os.path.abspath(output_folder)}\")\n",
    "    print(f\"Train ratio: {train_ratio}\")\n",
    "\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"Error: Source folder '{source_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    train_dir = os.path.join(output_folder, 'train')\n",
    "    test_dir = os.path.join(output_folder, 'test')\n",
    "\n",
    "    try:\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "        print(f\"Created base directories: '{train_dir}' and '{test_dir}'\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directories: {e}\")\n",
    "        return\n",
    "\n",
    "    for class_name in os.listdir(source_folder):\n",
    "        source_class_path = os.path.join(source_folder, class_name)\n",
    "\n",
    "        if os.path.isdir(source_class_path):\n",
    "            print(f\"\\nProcessing class: {class_name}\")\n",
    "            train_class_path = os.path.join(train_dir, class_name)\n",
    "            test_class_path = os.path.join(test_dir, class_name)\n",
    "            os.makedirs(train_class_path, exist_ok=True)\n",
    "            os.makedirs(test_class_path, exist_ok=True)\n",
    "            try:\n",
    "                all_files = [\n",
    "                    f for f in os.listdir(source_class_path)\n",
    "                    if os.path.isfile(os.path.join(source_class_path, f))\n",
    "                ]\n",
    "            except OSError as e:\n",
    "                print(f\"Warning: Could not read files in {source_class_path}. Skipping. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            if not all_files:\n",
    "                print(f\"Warning: No files found in {source_class_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            random.shuffle(all_files)\n",
    "\n",
    "            split_index = math.floor(len(all_files) * train_ratio)\n",
    "            train_files = all_files[:split_index]\n",
    "            test_files = all_files[split_index:]\n",
    "\n",
    "            print(f\"Total files: {len(all_files)}\")\n",
    "            print(f\"Train files: {len(train_files)}\")\n",
    "            print(f\"Test files : {len(test_files)}\")\n",
    "\n",
    "            print(f\"Copying {len(train_files)} files to {train_class_path}...\")\n",
    "            copied_train = 0\n",
    "            for file_name in train_files:\n",
    "                source_file_path = os.path.join(source_class_path, file_name)\n",
    "                dest_file_path = os.path.join(train_class_path, file_name)\n",
    "                try:\n",
    "                    shutil.copy2(source_file_path, dest_file_path)\n",
    "                    copied_train += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error copying {source_file_path} to {dest_file_path}: {e}\")\n",
    "            if copied_train != len(train_files):\n",
    "                 print(f\"Warning: Only {copied_train} out of {len(train_files)} train files were copied successfully.\")\n",
    "\n",
    "            print(f\"Copying {len(test_files)} files to {test_class_path}...\")\n",
    "            copied_test = 0\n",
    "            for file_name in test_files:\n",
    "                source_file_path = os.path.join(source_class_path, file_name)\n",
    "                dest_file_path = os.path.join(test_class_path, file_name)\n",
    "                try:\n",
    "                    shutil.copy2(source_file_path, dest_file_path)\n",
    "                    copied_test += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error copying {source_file_path} to {dest_file_path}: {e}\")\n",
    "            if copied_test != len(test_files):\n",
    "                 print(f\"Warning: Only {copied_test} out of {len(test_files)} test files were copied successfully.\")\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping '{class_name}' as it is not a directory.\")\n",
    "\n",
    "    print(\"\\nData splitting complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"D:\\\\Study\\\\resics_applied_ml_project\\\\pytorch_data\\\\NWPU-RESISC45\"\n",
    "output_directory = \"D:\\\\Study\\\\resics_applied_ml_project\\\\splitted_data\"\n",
    "training_ratio = 0.8\n",
    "if 'path/to/your' in source_directory or 'path/to/your' in output_directory:\n",
    "    print(\"=\"*50)\n",
    "    print(\"ERROR: Please update the 'source_directory' and 'output_directory'\")\n",
    "    print(\"variables in the script with your actual folder paths.\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    split_data(source_directory, output_directory, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c98fa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e83a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"D:\\\\Study\\\\resics_applied_ml_project\\\\splitted_data\")\n",
    "train_dir = image_path / \"train/\"\n",
    "test_dir = image_path / \"test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b59ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = os.cpu_count()\n",
    "def create_dataloaders(\n",
    "    train_dir: str, \n",
    "    test_dir: str, \n",
    "    transform: transforms.Compose, \n",
    "    batch_size: int, \n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "  \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "  Takes in a training directory and testing directory path and turns\n",
    "  them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "  Args:\n",
    "    train_dir: Path to training directory.\n",
    "    test_dir: Path to testing directory.\n",
    "    transform: torchvision transforms to perform on training and testing data.\n",
    "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "    num_workers: An integer for number of workers per DataLoader.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "    Where class_names is a list of the target classes.\n",
    "    Example usage:\n",
    "      train_dataloader, test_dataloader, class_names = \\\n",
    "        = create_dataloaders(train_dir=path/to/train_dir,\n",
    "                             test_dir=path/to/test_dir,\n",
    "                             transform=some_transform,\n",
    "                             batch_size=32,\n",
    "                             num_workers=4)\n",
    "  \"\"\"\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  train_dataloader = DataLoader(\n",
    "      train_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "      test_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e5c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2052717d2d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2052717e5c0>,\n",
       " ['airplane',\n",
       "  'airport',\n",
       "  'baseball_diamond',\n",
       "  'basketball_court',\n",
       "  'beach',\n",
       "  'bridge',\n",
       "  'chaparral',\n",
       "  'church',\n",
       "  'circular_farmland',\n",
       "  'cloud',\n",
       "  'commercial_area',\n",
       "  'dense_residential',\n",
       "  'desert',\n",
       "  'forest',\n",
       "  'freeway',\n",
       "  'golf_course',\n",
       "  'ground_track_field',\n",
       "  'harbor',\n",
       "  'industrial_area',\n",
       "  'intersection',\n",
       "  'island',\n",
       "  'lake',\n",
       "  'meadow',\n",
       "  'medium_residential',\n",
       "  'mobile_home_park',\n",
       "  'mountain',\n",
       "  'overpass',\n",
       "  'palace',\n",
       "  'parking_lot',\n",
       "  'railway',\n",
       "  'railway_station',\n",
       "  'rectangular_farmland',\n",
       "  'river',\n",
       "  'roundabout',\n",
       "  'runway',\n",
       "  'sea_ice',\n",
       "  'ship',\n",
       "  'snowberg',\n",
       "  'sparse_residential',\n",
       "  'stadium',\n",
       "  'storage_tank',\n",
       "  'tennis_court',\n",
       "  'terrace',\n",
       "  'thermal_power_station',\n",
       "  'wetland'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=manual_transforms, \n",
    "                                                                               batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f9a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76cf8ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[232]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ea776",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = create_dataloaders(train_dir=train_dir,\n",
    "                                        test_dir=test_dir,\n",
    "                                        transform=auto_transforms,\n",
    "                                        batch_size=32)\n",
    "\n",
    "assert type(a) is type(train_dataloader) \n",
    "assert type(b) is type(test_dataloader) \n",
    "assert type(c) is type(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3582f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(weights=weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc20015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 45)\n",
    "model = model.to(device)\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889aa686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "ResNet (ResNet)                          [32, 3, 224, 224]    [32, 45]             --                   Partial\n",
       "├─Conv2d (conv1)                         [32, 3, 224, 224]    [32, 64, 112, 112]   (9,408)              False\n",
       "├─BatchNorm2d (bn1)                      [32, 64, 112, 112]   [32, 64, 112, 112]   (128)                False\n",
       "├─ReLU (relu)                            [32, 64, 112, 112]   [32, 64, 112, 112]   --                   --\n",
       "├─MaxPool2d (maxpool)                    [32, 64, 112, 112]   [32, 64, 56, 56]     --                   --\n",
       "├─Sequential (layer1)                    [32, 64, 56, 56]     [32, 256, 56, 56]    --                   False\n",
       "│    └─Bottleneck (0)                    [32, 64, 56, 56]     [32, 256, 56, 56]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 56, 56]     [32, 64, 56, 56]     (4,096)              False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
       "│    │    └─Sequential (downsample)      [32, 64, 56, 56]     [32, 256, 56, 56]    (16,896)             False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
       "│    └─Bottleneck (1)                    [32, 256, 56, 56]    [32, 256, 56, 56]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 64, 56, 56]     (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
       "│    └─Bottleneck (2)                    [32, 256, 56, 56]    [32, 256, 56, 56]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 64, 56, 56]     (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 56, 56]     [32, 64, 56, 56]     (36,864)             False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 56, 56]     [32, 64, 56, 56]     (128)                False\n",
       "│    │    └─ReLU (relu)                  [32, 64, 56, 56]     [32, 64, 56, 56]     --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 64, 56, 56]     [32, 256, 56, 56]    (16,384)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 256, 56, 56]    [32, 256, 56, 56]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 56, 56]    [32, 256, 56, 56]    --                   --\n",
       "├─Sequential (layer2)                    [32, 256, 56, 56]    [32, 512, 28, 28]    --                   False\n",
       "│    └─Bottleneck (0)                    [32, 256, 56, 56]    [32, 512, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 56, 56]    [32, 128, 56, 56]    (32,768)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 56, 56]    [32, 128, 56, 56]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 56, 56]    [32, 128, 56, 56]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 56, 56]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
       "│    │    └─Sequential (downsample)      [32, 256, 56, 56]    [32, 512, 28, 28]    (132,096)            False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
       "│    └─Bottleneck (1)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
       "│    └─Bottleneck (2)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
       "│    └─Bottleneck (3)                    [32, 512, 28, 28]    [32, 512, 28, 28]    --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 128, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 28, 28]    [32, 128, 28, 28]    (147,456)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 28, 28]    [32, 128, 28, 28]    (256)                False\n",
       "│    │    └─ReLU (relu)                  [32, 128, 28, 28]    [32, 128, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 128, 28, 28]    [32, 512, 28, 28]    (65,536)             False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 512, 28, 28]    [32, 512, 28, 28]    (1,024)              False\n",
       "│    │    └─ReLU (relu)                  [32, 512, 28, 28]    [32, 512, 28, 28]    --                   --\n",
       "├─Sequential (layer3)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   --                   False\n",
       "│    └─Bottleneck (0)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 28, 28]    [32, 256, 28, 28]    (131,072)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 28, 28]    [32, 256, 28, 28]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 28, 28]    [32, 256, 28, 28]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 28, 28]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─Sequential (downsample)      [32, 512, 28, 28]    [32, 1024, 14, 14]   (526,336)            False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "│    └─Bottleneck (1)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "│    └─Bottleneck (2)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "│    └─Bottleneck (3)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "│    └─Bottleneck (4)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "│    └─Bottleneck (5)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 256, 14, 14]    (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 14, 14]    [32, 256, 14, 14]    (589,824)            False\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 14, 14]    [32, 256, 14, 14]    (512)                False\n",
       "│    │    └─ReLU (relu)                  [32, 256, 14, 14]    [32, 256, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 256, 14, 14]    [32, 1024, 14, 14]   (262,144)            False\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 1024, 14, 14]   [32, 1024, 14, 14]   (2,048)              False\n",
       "│    │    └─ReLU (relu)                  [32, 1024, 14, 14]   [32, 1024, 14, 14]   --                   --\n",
       "├─Sequential (layer4)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     --                   True\n",
       "│    └─Bottleneck (0)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 1024, 14, 14]   [32, 512, 14, 14]    524,288              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 14, 14]    [32, 512, 14, 14]    1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 14, 14]    [32, 512, 14, 14]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 14, 14]    [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     1,048,576            True\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     4,096                True\n",
       "│    │    └─Sequential (downsample)      [32, 1024, 14, 14]   [32, 2048, 7, 7]     2,101,248            True\n",
       "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
       "│    └─Bottleneck (1)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]     [32, 512, 7, 7]      1,048,576            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     1,048,576            True\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     4,096                True\n",
       "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
       "│    └─Bottleneck (2)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 2048, 7, 7]     [32, 512, 7, 7]      1,048,576            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 7, 7]      [32, 512, 7, 7]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 7, 7]      [32, 512, 7, 7]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 7, 7]      [32, 512, 7, 7]      --                   --\n",
       "│    │    └─Conv2d (conv3)               [32, 512, 7, 7]      [32, 2048, 7, 7]     1,048,576            True\n",
       "│    │    └─BatchNorm2d (bn3)            [32, 2048, 7, 7]     [32, 2048, 7, 7]     4,096                True\n",
       "│    │    └─ReLU (relu)                  [32, 2048, 7, 7]     [32, 2048, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [32, 2048, 7, 7]     [32, 2048, 1, 1]     --                   --\n",
       "├─Linear (fc)                            [32, 2048]           [32, 45]             92,205               True\n",
       "========================================================================================================================\n",
       "Total params: 23,600,237\n",
       "Trainable params: 15,056,941\n",
       "Non-trainable params: 8,543,296\n",
       "Total mult-adds (G): 130.79\n",
       "========================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5690.37\n",
       "Params size (MB): 94.40\n",
       "Estimated Total Size (MB): 5804.04\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        # col_names=[\"input_size\"],\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bec36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Trains a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to training mode and then\n",
    "  runs through all of the required training steps (forward\n",
    "  pass, loss calculation, optimizer step).\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained.\n",
    "    dataloader: A DataLoader instance for the model to be trained on.\n",
    "    loss_fn: A PyTorch loss function to minimize.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of training loss and training accuracy metrics.\n",
    "    In the form (train_loss, train_accuracy). For example:\n",
    "\n",
    "    (0.1112, 0.8743)\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "\n",
    "  train_loss, train_acc = 0, 0\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      y_pred = model(X)\n",
    "      loss = loss_fn(y_pred, y)\n",
    "      train_loss += loss.item()\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "  train_loss = train_loss / len(dataloader)\n",
    "  train_acc = train_acc / len(dataloader)\n",
    "  return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "  \"\"\"Tests a PyTorch model for a single epoch.\n",
    "\n",
    "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
    "  a forward pass on a testing dataset.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be tested.\n",
    "    dataloader: A DataLoader instance for the model to be tested on.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A tuple of testing loss and testing accuracy metrics.\n",
    "    In the form (test_loss, test_accuracy). For example:\n",
    "\n",
    "    (0.0223, 0.8985)\n",
    "  \"\"\"\n",
    "  model.eval() \n",
    "\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  with torch.inference_mode():\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "          X, y = X.to(device), y.to(device)\n",
    "\n",
    "          test_pred_logits = model(X)\n",
    "\n",
    "          loss = loss_fn(test_pred_logits, y)\n",
    "          test_loss += loss.item()\n",
    "\n",
    "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "  test_loss = test_loss / len(dataloader)\n",
    "  test_acc = test_acc / len(dataloader)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "  \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "  Passes a target PyTorch models through train_step() and test_step()\n",
    "  functions for a number of epochs, training and testing the model\n",
    "  in the same epoch loop.\n",
    "\n",
    "  Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "  Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "                  train_acc: [...],\n",
    "                  test_loss: [...],\n",
    "                  test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "                 {train_loss: [2.0616, 1.0537],\n",
    "                  train_acc: [0.3945, 0.3945],\n",
    "                  test_loss: [1.2641, 1.5706],\n",
    "                  test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "  results = {\"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "  }\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "      test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "\n",
    "      print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "      )\n",
    "\n",
    "      results[\"train_loss\"].append(train_loss)\n",
    "      results[\"train_acc\"].append(train_acc)\n",
    "      results[\"test_loss\"].append(test_loss)\n",
    "      results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb61cf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99a157cebde4fe386e1dad6d6e3ba48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.3132 | train_acc: 0.7129 | test_loss: 0.7284 | test_acc: 0.8237\n",
      "Epoch: 2 | train_loss: 0.6282 | train_acc: 0.8376 | test_loss: 0.5646 | test_acc: 0.8516\n",
      "Epoch: 3 | train_loss: 0.4893 | train_acc: 0.8667 | test_loss: 0.4924 | test_acc: 0.8646\n",
      "Epoch: 4 | train_loss: 0.4090 | train_acc: 0.8892 | test_loss: 0.4526 | test_acc: 0.8751\n",
      "Epoch: 5 | train_loss: 0.3535 | train_acc: 0.9028 | test_loss: 0.4216 | test_acc: 0.8746\n",
      "Epoch: 6 | train_loss: 0.3114 | train_acc: 0.9140 | test_loss: 0.4481 | test_acc: 0.8736\n",
      "Epoch: 7 | train_loss: 0.2788 | train_acc: 0.9243 | test_loss: 0.4035 | test_acc: 0.8832\n",
      "Epoch: 8 | train_loss: 0.2556 | train_acc: 0.9314 | test_loss: 0.4306 | test_acc: 0.8770\n",
      "Epoch: 9 | train_loss: 0.2343 | train_acc: 0.9369 | test_loss: 0.4068 | test_acc: 0.8808\n",
      "Epoch: 10 | train_loss: 0.2197 | train_acc: 0.9392 | test_loss: 0.4000 | test_acc: 0.8827\n",
      "Epoch: 11 | train_loss: 0.2012 | train_acc: 0.9444 | test_loss: 0.3760 | test_acc: 0.8862\n",
      "Epoch: 12 | train_loss: 0.1883 | train_acc: 0.9490 | test_loss: 0.3877 | test_acc: 0.8835\n",
      "Epoch: 13 | train_loss: 0.1692 | train_acc: 0.9561 | test_loss: 0.3846 | test_acc: 0.8873\n",
      "Epoch: 14 | train_loss: 0.1667 | train_acc: 0.9557 | test_loss: 0.3753 | test_acc: 0.8882\n",
      "Epoch: 15 | train_loss: 0.1550 | train_acc: 0.9578 | test_loss: 0.3916 | test_acc: 0.8838\n",
      "Epoch: 16 | train_loss: 0.1468 | train_acc: 0.9610 | test_loss: 0.3840 | test_acc: 0.8831\n",
      "Epoch: 17 | train_loss: 0.1430 | train_acc: 0.9597 | test_loss: 0.4178 | test_acc: 0.8864\n",
      "Epoch: 18 | train_loss: 0.1313 | train_acc: 0.9650 | test_loss: 0.4247 | test_acc: 0.8829\n",
      "Epoch: 19 | train_loss: 0.1307 | train_acc: 0.9642 | test_loss: 0.4051 | test_acc: 0.8841\n",
      "Epoch: 20 | train_loss: 0.1231 | train_acc: 0.9675 | test_loss: 0.3690 | test_acc: 0.8874\n",
      "[INFO] Total training time: 3785.581 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "results = train(model=model,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       test_dataloader=test_dataloader,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_fn=loss_fn,\n",
    "                       epochs=20,\n",
    "                       device=device)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a34bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./output\\trained_resnet50_model.pth\n",
      "Training results saved to ./output\\training_results.pth\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(output_dir, \"trained_resnet50_model.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "results_save_path = os.path.join(output_dir, \"training_results.pth\")\n",
    "torch.save(results, results_save_path)\n",
    "print(f\"Training results saved to {results_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af6136",
   "metadata": {},
   "source": [
    "The following part with model loading should be tested in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "\n",
    "# model_load_path = \"./output/trained_resnet50_model.pth\"  # Ensure this matches where you saved it\n",
    "\n",
    "# weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "# model = torchvision.models.resnet50(weights=weights).to(device)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = torch.nn.Linear(num_ftrs, 45)\n",
    "# model = model.to(device)\n",
    "# for param in model.layer4.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# loaded_model_state_dict = torch.load(model_load_path)\n",
    "\n",
    "# model.load_state_dict(loaded_model_state_dict)\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# results_load_path = \"./output/training_results.pth\"\n",
    "# loaded_results = torch.load(results_load_path)\n",
    "# print(\"Training results loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
